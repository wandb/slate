
<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta content="IE=edge,chrome=1" http-equiv="X-UA-Compatible">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <title>API Reference</title>
    <link href="images/favicon.png" rel="icon" type="image/png" />


    <style>
      .highlight table td { padding: 5px; }
.highlight table pre { margin: 0; }
.highlight .gh {
  color: #999999;
}
.highlight .sr {
  color: #f6aa11;
}
.highlight .go {
  color: #888888;
}
.highlight .gp {
  color: #555555;
}
.highlight .gs {
}
.highlight .gu {
  color: #aaaaaa;
}
.highlight .nb {
  color: #f6aa11;
}
.highlight .cm {
  color: #75715e;
}
.highlight .cp {
  color: #75715e;
}
.highlight .c1 {
  color: #75715e;
}
.highlight .cs {
  color: #75715e;
}
.highlight .c, .highlight .cd {
  color: #75715e;
}
.highlight .err {
  color: #960050;
}
.highlight .gr {
  color: #960050;
}
.highlight .gt {
  color: #960050;
}
.highlight .gd {
  color: #49483e;
}
.highlight .gi {
  color: #49483e;
}
.highlight .ge {
  color: #49483e;
}
.highlight .kc {
  color: #66d9ef;
}
.highlight .kd {
  color: #66d9ef;
}
.highlight .kr {
  color: #66d9ef;
}
.highlight .no {
  color: #66d9ef;
}
.highlight .kt {
  color: #66d9ef;
}
.highlight .mf {
  color: #ae81ff;
}
.highlight .mh {
  color: #ae81ff;
}
.highlight .il {
  color: #ae81ff;
}
.highlight .mi {
  color: #ae81ff;
}
.highlight .mo {
  color: #ae81ff;
}
.highlight .m, .highlight .mb, .highlight .mx {
  color: #ae81ff;
}
.highlight .sc {
  color: #ae81ff;
}
.highlight .se {
  color: #ae81ff;
}
.highlight .ss {
  color: #ae81ff;
}
.highlight .sd {
  color: #e6db74;
}
.highlight .s2 {
  color: #e6db74;
}
.highlight .sb {
  color: #e6db74;
}
.highlight .sh {
  color: #e6db74;
}
.highlight .si {
  color: #e6db74;
}
.highlight .sx {
  color: #e6db74;
}
.highlight .s1 {
  color: #e6db74;
}
.highlight .s {
  color: #e6db74;
}
.highlight .na {
  color: #a6e22e;
}
.highlight .nc {
  color: #a6e22e;
}
.highlight .nd {
  color: #a6e22e;
}
.highlight .ne {
  color: #a6e22e;
}
.highlight .nf {
  color: #a6e22e;
}
.highlight .vc {
  color: #ffffff;
}
.highlight .nn {
  color: #ffffff;
}
.highlight .nl {
  color: #ffffff;
}
.highlight .ni {
  color: #ffffff;
}
.highlight .bp {
  color: #ffffff;
}
.highlight .vg {
  color: #ffffff;
}
.highlight .vi {
  color: #ffffff;
}
.highlight .nv {
  color: #ffffff;
}
.highlight .w {
  color: #ffffff;
}
.highlight {
  color: #ffffff;
}
.highlight .n, .highlight .py, .highlight .nx {
  color: #ffffff;
}
.highlight .ow {
  color: #f92672;
}
.highlight .nt {
  color: #f92672;
}
.highlight .k, .highlight .kv {
  color: #f92672;
}
.highlight .kn {
  color: #f92672;
}
.highlight .kp {
  color: #f92672;
}
.highlight .o {
  color: #f92672;
}
    </style>
    <link href="stylesheets/screen.css" rel="stylesheet" media="screen" />
    <link href="stylesheets/print.css" rel="stylesheet" media="print" />
      <script src="javascripts/all.js"></script>
  </head>

  <body class="index" data-languages="[&quot;python--tensorflow&quot;,&quot;python--keras&quot;,&quot;python--pytorch&quot;,&quot;java--spark&quot;]">
    <a href="#" id="nav-button">
      <span>
        NAV
        <img src="images/navbar.png" alt="Navbar" />
      </span>
    </a>
    <div class="toc-wrapper">
      <img src="images/logo.png" class="logo" alt="Logo" />
        <div class="lang-selector">
              <a href="#" data-language-name="python--tensorflow">TensorFlow</a>
              <a href="#" data-language-name="python--keras">Keras</a>
              <a href="#" data-language-name="python--pytorch">Pytorch</a>
              <a href="#" data-language-name="java--spark">Spark</a>
        </div>
        <div class="search">
          <input type="text" class="search" id="input-search" placeholder="Search">
        </div>
        <ul class="search-results"></ul>
      <div id="toc" class="toc-list-h1">
          <li>
            <a href="#introduction" class="toc-h1 toc-link" data-title="Introduction">Introduction</a>
          </li>
          <li>
            <a href="#getting-started" class="toc-h1 toc-link" data-title="Getting started">Getting started</a>
          </li>
          <li>
            <a href="#tracking-models" class="toc-h1 toc-link" data-title="Tracking Models">Tracking Models</a>
              <ul class="toc-list-h2">
                  <li>
                    <a href="#configurations" class="toc-h2 toc-link" data-title="Configurations">Configurations</a>
                  </li>
                  <li>
                    <a href="#metrics" class="toc-h2 toc-link" data-title="Metrics">Metrics</a>
                  </li>
                  <li>
                    <a href="#saving-models" class="toc-h2 toc-link" data-title="Saving Models">Saving Models</a>
                  </li>
                  <li>
                    <a href="#saving-code-state" class="toc-h2 toc-link" data-title="Saving Code State">Saving Code State</a>
                  </li>
              </ul>
          </li>
          <li>
            <a href="#hyperparamer-search" class="toc-h1 toc-link" data-title="Hyperparamer Search">Hyperparamer Search</a>
          </li>
      </div>
        <ul class="toc-footer">
            <li><a href='https://wandb.ai'>Login to wandb</a></li>
        </ul>
    </div>
    <div class="page-wrapper">
      <div class="dark-box"></div>
      <div class="content">
        <h1 id='introduction'>Introduction</h1><pre class="highlight shell tab-shell"><code><span class="c"># Install wandb</span>
pip install wandb
</code></pre>
<p>WandB is a productivity tool for building machine learning models.  We help you
track everything you do, visualize your results and automate large-scale hyperparameter search.</p>
<h1 id='getting-started'>Getting started</h1><pre class="highlight shell tab-shell"><code><span class="c"># Initialize wandb in the root directory of your project</span>
wandb init
</code></pre>
<blockquote>
<p>Near the top of your code add initialization code:</p>
</blockquote>
<pre class="highlight python tab-python"><code><span class="c"># Inside my model training code</span>
<span class="kn">import</span> <span class="nn">wandb</span>
<span class="n">run</span> <span class="o">=</span> <span class="n">wandb</span><span class="o">.</span><span class="n">init</span><span class="p">()</span>

<span class="c"># Run my complicated training loop...</span>
</code></pre>
<blockquote>
<p>Modify your command to run training</p>
</blockquote>
<pre class="highlight shell tab-shell"><code><span class="c"># The old way to run your training script (still works, but no magic)</span>
python learn.py
</code></pre><pre class="highlight shell tab-shell"><code><span class="c"># The new way to run your training script (saves logs, and so much more...)</span>
wandb run learn.py
</code></pre>
<p>It&#39;s easy to configure WandB to work with one of your projects.  </p>

<p>Sign up for an account at <a href="https://wandb.ai">https://wandb.ai</a></p>

<p>You will be prompted for a team name and a project name.  This will create a
wandb directory that contains a settings file with your entity name and
project name.</p>

<p>Now you every time you run your training script with wandb, a new record will
be added to https://wandb.ai/$ENTITY_NAME/$PROJECT_NAME.  Your training logs
will be saved along with a snapshot of your latest commit.</p>

<aside class="notice">
You can always rerun *wandb init* to change your project's settings.
</aside>
<h1 id='tracking-models'>Tracking Models</h1><h2 id='configurations'>Configurations</h2><pre class="highlight python tab-python--tensorflow"><code><span class="n">run</span> <span class="o">=</span> <span class="n">wandb</span><span class="o">.</span><span class="n">init</span><span class="p">()</span>
<span class="n">config</span> <span class="o">=</span> <span class="n">run</span><span class="o">.</span><span class="n">config</span> <span class="c"># get the config object</span>
<span class="n">config</span><span class="o">.</span><span class="n">epochs</span> <span class="o">=</span> <span class="mi">4</span>   <span class="c"># config variables are saved to the cloud</span>
                    <span class="c"># with a run every time they're set</span>

<span class="n">flags</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">app</span><span class="o">.</span><span class="n">flags</span>
<span class="n">flags</span><span class="o">.</span><span class="n">DEFINE_string</span><span class="p">(</span><span class="s">'data_dir'</span><span class="p">,</span> <span class="s">'/tmp/data'</span><span class="p">)</span>
<span class="n">flags</span><span class="o">.</span><span class="n">DEFINE_integer</span><span class="p">(</span><span class="s">'batch_size'</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="s">'Batch size.'</span><span class="p">)</span>
<span class="n">config</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">flags</span><span class="o">.</span><span class="n">FLAGS</span><span class="p">)</span>  <span class="c"># adds all of the tensorflow flags as config variables</span>
</code></pre><pre class="highlight python tab-python--keras"><code><span class="n">run</span> <span class="o">=</span> <span class="n">wandb</span><span class="o">.</span><span class="n">init</span><span class="p">()</span>
<span class="n">config</span> <span class="o">=</span> <span class="n">run</span><span class="o">.</span><span class="n">config</span> <span class="c"># get the config object</span>
<span class="n">config</span><span class="o">.</span><span class="n">epochs</span> <span class="o">=</span> <span class="mi">4</span>   <span class="c"># config variables are saved to the cloud</span>
                    <span class="c"># with a run every time they're set</span>

<span class="n">parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">()</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s">'--batch-size'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">metavar</span><span class="o">=</span><span class="s">'N'</span><span class="p">,</span>
                     <span class="n">help</span><span class="o">=</span><span class="s">'input batch size for training (default: 8)'</span><span class="p">)</span>
<span class="n">config</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">args</span><span class="p">)</span> <span class="c"># adds all of the arguments as config variables</span>
</code></pre><pre class="highlight python tab-python--pytorch"><code><span class="n">run</span> <span class="o">=</span> <span class="n">wandb</span><span class="o">.</span><span class="n">init</span><span class="p">()</span>
<span class="n">config</span> <span class="o">=</span> <span class="n">run</span><span class="o">.</span><span class="n">config</span> <span class="c"># get the config object</span>
<span class="n">config</span><span class="o">.</span><span class="n">epochs</span> <span class="o">=</span> <span class="mi">4</span>   <span class="c"># config variables are saved to the cloud</span>
                    <span class="c"># with a run every time they're set</span>

<span class="n">parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">()</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s">'--batch-size'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">metavar</span><span class="o">=</span><span class="s">'N'</span><span class="p">,</span>
                     <span class="n">help</span><span class="o">=</span><span class="s">'input batch size for training (default: 8)'</span><span class="p">)</span>
<span class="n">config</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">args</span><span class="p">)</span> <span class="c"># adds all of the arguments as config variables</span>
</code></pre>
<p>Configurations is a way of automatically tracking the hyperparameters you used
to build your model.</p>

<p>You can set the configuration values directly and access them as ordinary variables, or
you can import variables from tensorflow flags or argparse objects to integrate
with pre-existing code.</p>
<h3 id='file-based-configs'>File-Based Configs</h3>
<blockquote>
<p>(Optional) Create a config-defaults file to automatically load hyperparameters
into the config variable.</p>
</blockquote>
<pre class="highlight yaml tab-yaml"><code><span class="c1"># sample config-defaults file</span>
<span class="na">epochs</span><span class="pi">:</span>
  <span class="na">desc</span><span class="pi">:</span> <span class="s">Number of epochs to train over</span>
  <span class="na">value</span><span class="pi">:</span> <span class="s">100</span>
<span class="na">batch_size</span><span class="pi">:</span>
  <span class="na">desc</span><span class="pi">:</span> <span class="s">Size of each mini-batch</span>
  <span class="na">value</span><span class="pi">:</span> <span class="s">32</span>
</code></pre>
<p>You can create a file called config-defaults.yaml and it will automatically
be loaded into the config variable.</p>

<p>You can tell wandb to load different config files with the command</p>

<blockquote>
<p>Automatically load the yaml file into the config object</p>
</blockquote>
<pre class="highlight shell tab-shell"><code>wandb run train.py
</code></pre>
<blockquote>
<p>Change the config file used to load the config object</p>
</blockquote>
<pre class="highlight shell tab-shell"><code>wandb run --configs special-configs.yaml
</code></pre>
<blockquote>
<p>Mutiple config files are allowed are allowed</p>
</blockquote>
<pre class="highlight shell tab-shell"><code>wandb run --configs special-configs.yaml,extra-configs.yaml
</code></pre><h2 id='metrics'>Metrics</h2><pre class="highlight python tab-python--tensorflow"><code><span class="n">run</span> <span class="o">=</span> <span class="n">wandb</span><span class="o">.</span><span class="n">init</span><span class="p">()</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">run</span><span class="o">.</span><span class="n">history</span>
<span class="n">summary</span> <span class="o">=</span> <span class="n">run</span><span class="o">.</span><span class="n">summary</span>

<span class="c"># Start training</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
  <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">init</span><span class="p">)</span>

  <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">FLAGS</span><span class="o">.</span><span class="n">num_steps</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
      <span class="n">batch_x</span><span class="p">,</span> <span class="n">batch_y</span> <span class="o">=</span> <span class="n">mnist</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">next_batch</span><span class="p">(</span><span class="n">FLAGS</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>
      <span class="c"># Run optimization op (backprop)</span>
      <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">train_op</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">X</span><span class="p">:</span> <span class="n">batch_x</span><span class="p">,</span> <span class="n">Y</span><span class="p">:</span> <span class="n">batch_y</span><span class="p">})</span>
      <span class="c"># Calculate batch loss and accuracy</span>
      <span class="n">loss</span><span class="p">,</span> <span class="n">acc</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">loss_op</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">],</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">X</span><span class="p">:</span> <span class="n">batch_x</span><span class="p">,</span>
                                                               <span class="n">Y</span><span class="p">:</span> <span class="n">batch_y</span><span class="p">})</span>

      <span class="n">history</span><span class="o">.</span><span class="n">add</span><span class="p">({</span><span class="s">'acc'</span><span class="p">:</span> <span class="n">acc</span><span class="p">,</span> <span class="s">'loss'</span><span class="p">:</span><span class="n">loss</span><span class="p">})</span>   <span class="c"># log accuracy and loss</span>
      <span class="n">summary</span><span class="p">[</span><span class="s">'acc'</span><span class="p">]</span> <span class="o">=</span> <span class="n">acc</span>  
      <span class="n">summary</span><span class="p">[</span><span class="s">'loss'</span><span class="p">]</span> <span class="o">=</span> <span class="n">loss</span>

</code></pre><pre class="highlight python tab-python--keras"><code>
<span class="n">run</span> <span class="o">=</span> <span class="n">wandb</span><span class="o">.</span><span class="n">init</span><span class="p">()</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">run</span><span class="o">.</span><span class="n">history</span>
<span class="n">summary</span> <span class="o">=</span> <span class="n">run</span><span class="o">.</span><span class="n">summary</span>

<span class="k">def</span> <span class="nf">log_discriminator</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="p">):</span>
  <span class="n">history</span><span class="o">.</span><span class="n">add</span><span class="p">({</span>
            <span class="s">'loss'</span><span class="p">:</span> <span class="n">logs</span><span class="p">[</span><span class="s">'loss'</span><span class="p">],</span>
            <span class="s">'acc'</span><span class="p">:</span> <span class="n">logs</span><span class="p">[</span><span class="s">'acc'</span><span class="p">]})</span>
  <span class="n">summary</span><span class="p">[</span><span class="s">'acc'</span><span class="p">]</span> <span class="o">=</span> <span class="n">logs</span><span class="p">[</span><span class="s">'acc'</span><span class="p">])</span>


<span class="n">wandb_logging_callback</span> <span class="o">=</span> <span class="n">LambdaCallback</span><span class="p">(</span><span class="n">on_epoch_end</span><span class="o">=</span><span class="n">log_generator</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">wandb_logging_callback</span><span class="p">])</span>
</code></pre><pre class="highlight python tab-python--pytorch"><code><span class="n">run</span> <span class="o">=</span> <span class="n">wandb</span><span class="o">.</span><span class="n">init</span><span class="p">()</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">run</span><span class="o">.</span><span class="n">history</span>
<span class="n">summary</span> <span class="o">=</span> <span class="n">run</span><span class="o">.</span><span class="n">summary</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">epochs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
  <span class="n">train_loss</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>
  <span class="n">test_loss</span><span class="p">,</span> <span class="n">test_accuracy</span> <span class="o">=</span> <span class="n">test</span><span class="p">()</span>

  <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="s">'model'</span><span class="p">)</span>

  <span class="n">history</span><span class="o">.</span><span class="n">add</span><span class="p">({</span><span class="s">"Train Loss"</span><span class="p">:</span> <span class="n">train_loss</span><span class="p">,</span>
                   <span class="s">"Test Loss"</span><span class="p">:</span> <span class="n">test_loss</span><span class="p">})</span>
  <span class="n">summary</span><span class="p">[</span><span class="s">"Test Accuracy"</span><span class="p">]</span> <span class="o">=</span> <span class="n">test_accuracy</span>

</code></pre>
<p>Metrics are a way of automatically tracking information about how the model
is performing.</p>
<h3 id='history'>History</h3>
<p>The history object is used to track metrics that change as the model runs.  Every
time the history object is updated the metrics are tracked.</p>
<h3 id='summary'>Summary</h3>
<p>The summary statistics are used to track single metrics per model.  If a summary
metric is modified, only the updated state is saved.</p>
<h3 id='keras-callback'>Keras Callback</h3>
<blockquote>
<p>Simpler way to track metrics in keras using WandbKerasCallback</p>
</blockquote>
<pre class="highlight python tab-python--keras"><code><span class="kn">import</span> <span class="nn">wandb</span>
<span class="kn">from</span> <span class="nn">wandb.wandb_keras</span> <span class="kn">import</span> <span class="n">WandbKerasCallback</span>

<span class="n">run</span> <span class="o">=</span> <span class="n">wandb</span><span class="o">.</span><span class="n">init</span><span class="p">()</span>
<span class="n">config</span> <span class="o">=</span> <span class="n">run</span><span class="o">.</span><span class="n">config</span>

<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span>  <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">),</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">WandbKerasCallback</span><span class="p">()])</span>
</code></pre>
<p>If you are using keras, you can use the WandbKerasCallback to automatically save
all the metrics and the loss values tracked in <code>model.fit</code>.</p>
<h2 id='saving-models'>Saving Models</h2><pre class="highlight python tab-python--keras"><code><span class="kn">import</span> <span class="nn">wandb</span>
<span class="kn">from</span> <span class="nn">wandb.wandb_keras</span> <span class="kn">import</span> <span class="n">WandbKerasCallback</span>

<span class="n">run</span> <span class="o">=</span> <span class="n">wandb</span><span class="o">.</span><span class="n">init</span><span class="p">()</span>

<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span>  <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">),</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">WandbKerasCallback</span><span class="p">()])</span>

<span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">run</span><span class="o">.</span><span class="nb">dir</span><span class="p">,</span> <span class="s">"model.h5"</span><span class="p">))</span> <span class="c">#</span>
</code></pre>
<p>Wandb will save to the cloud any files put in wandb&#39;s run directory.</p>

<p>Wandb&#39;s run directories are inside the wandb directory and the path looks like run-20171023_105053-3o4933r0 where 20171023_105053 is the timestamp and 3o4933r0
is the ID of the run.</p>
<h2 id='saving-code-state'>Saving Code State</h2>
<p>When training scripts are run with <code>wandb run train.py</code> from the command line
a link is saved to the last git commit.  A diff patch is also created to the state
of the code at the time run in case there are uncommitted changes.</p>
<pre class="highlight plaintext"><code># restores the code to the state it was in when run $RUN_ID was executed
wandb restore $RUN_ID
</code></pre><h1 id='hyperparamer-search'>Hyperparamer Search</h1>
      </div>
      <div class="dark-box">
          <div class="lang-selector">
                <a href="#" data-language-name="python--tensorflow">TensorFlow</a>
                <a href="#" data-language-name="python--keras">Keras</a>
                <a href="#" data-language-name="python--pytorch">Pytorch</a>
                <a href="#" data-language-name="java--spark">Spark</a>
          </div>
      </div>
    </div>
  </body>
</html>
